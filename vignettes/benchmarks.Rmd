---
title: "Benchmarks"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Benchmarks}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Measure the performance of different implementations of `cards` using `bench::mark()`.

```{r setup, message = FALSE, warning = FALSE}
library(cards)
library(reticulate)

phevaluator <- import("phevaluator")
```

# Data Frame

Benchmark the initial implementation using `data.frame` compared to an `integer()` approach similar
to [PH Evaluator](https://github.com/HenryRLee/PokerHandEvaluator)
[`card.py`](https://github.com/HenryRLee/PokerHandEvaluator/blob/master/python/phevaluator/card.py).

## New Deck

Create a new deck using `new_deck_df()` and an integer vector.

```{r new_deck_df}
deck <- new_deck_df()
deck_int <- 0:51
bench::mark(new_deck_df())
bench::mark(0:51)
```

While `new_deck_df()` is not designed to be called frequently, using an integer vector is much
faster.

## Deal

Compare performance of `deal_hand_df()` to sampling integers:

```{r deal_hand_df}
bench::mark(deal_hand_df(deck))
bench::mark(sample(deck_int, 5))
```

`deal_hand_df()` is about 7 times slower than `sample()`.

## Print

Test performance of `print_hand_df()` against a simple function that prints cards based on integers.

```{r print_hand_df}
test_hand <- deal_hand_df(deck)
bench::mark(print_hand_df(test_hand))

print_hand_int <- function(h) {
  cards <- paste0(rep(c(2:9, "T", "J", "Q", "K", "A"), each = 4), c("C", "D", "H", "S"))
  paste0(cards[h + 1], collapse = " ")
}
test_hand_int <- sample(0:51, 5)
bench::mark(print_hand_int(test_hand_int))
```

`print_hand_df()` is 14-15 times slower than the integer approach.

## Evaluate

Test performance of `eval_hand_df()` with a single hand and with randomly selected hands:

```{r eval_hand_df}
bench::mark(eval_hand_df(test_hand))
bench::mark(eval_hand_df(deal_hand_df(deck)))
```

As expected for a naive poker hand evaluator, performance of `eval_hand_df()` is poor compared to
fast algorithms.

## Summary

An implementation using integer would likely be much faster than the first implementation using
`data.frame`. Rank and suit can be derived using integer division and modulo arithmetic
respectively,and `tabulate()` is a faster replacement for `rle()`.

```{r rle_tabulate}
0:51 %/% 4
tabulate(0:51 %/% 4 + 1, 13)
0:51 %% 4
tabulate(0:51 %% 4 + 1, 4)

bench::mark(rle(sort(sample(0:51, 5) %/% 4 + 1)))
bench::mark(tabulate(sample(0:51, 5) %/% 4 + 1, 13))
```

Note that the tabulate approach is 7 times faster than sorting and run length encoding.

# Integer

Benchmark the second implementation using `integer()`.

## New Deck

Create a new deck using `new_deck()` and `new_deck_df()`.

```{r new_deck}
deck_df <- new_deck_df()
deck <- new_deck()
bench::mark(new_deck_df())
bench::mark(new_deck())
```

`new_deck()` is 90 times faster.

## Deal

Compare performance of `deal_hand_df()` and `deal_hand()`

```{r deal_hand}
bench::mark(deal_hand_df(deck_df))
bench::mark(deal_hand(deck))
```

`deal_hand()` is about 6 times faster.

## Print

Test performance of `print_hand_df()` against `print_hand()`.

```{r print_hand}
test_hand_df <- deal_hand_df(deck_df)
test_hand <- deal_hand(deck)

bench::mark(print_hand_df(test_hand_df))
bench::mark(print_hand(test_hand))
```

`print_hand()` is 16 times faster.

## Evaluate

Test performance of `eval_hand_df()` and `eval_hand()` with a single hand.

```{r eval_hand}
bench::mark(eval_hand_df(test_hand_df))
bench::mark(eval_hand(test_hand))
```

`eval_hand()` is 20 times faster, but should perform poorly compared to fast algorithms.

## Multiple Hands

Compare performance evaluating and printing multiple hands.

```{r readme}
bench::mark({
  deck <- new_deck_df()
  replicate(50, {
    hand <- deal_hand_df(deck)
    paste0(print_hand_df(hand), ": ", eval_hand_df(hand))
  })
})
bench::mark({
  deck <- new_deck()
  replicate(50, {
    hand <- deal_hand(deck)
    paste0(print_hand(hand), ": ", eval_hand(hand))
  })
})
```

Overall, the new implementation is 13-14 times faster.

# Python

Benchmark the `integer()` approach to
[PH Evaluator](https://github.com/HenryRLee/PokerHandEvaluator) using
[reticulate](https://rstudio.github.io/reticulate/index.html).

## Import

Test performance of `phevaluator` using `reticulate::import()`, starting with `sample_cards()`:

```{r sample_cards}
bench::mark(deal_hand(deck))
bench::mark(phevaluator$sample_cards(5L))
```

`phevaluator$sample_cards()` is 13 times slower than than the R integer implementation.

Also test `phevaluator$evaluate_card()` against the R integer method. `evaluate_card()` expects five
to seven integers passed as individual parameters.

```{r evaluate_card}
bench::mark(eval_hand(test_hand))
bench::mark(do.call(phevaluator$evaluate_cards, as.list(test_hand)))
```

Surprisingly, `phevaluator` is almost as slow as the original data frame implementation. Test again
using some specific hands and avoid the overhead of `do.call()` and `as.list()`:

```{r royal_flush}
four_aces <- c(51L, 50L, 49L, 48L, 47L)
royal_flush <- c(50L, 46L, 42L, 38L, 34L)

bench::mark(eval_hand(four_aces))
bench::mark(phevaluator$evaluate_cards(51L, 50L, 49L, 48L, 47L))

bench::mark(eval_hand(royal_flush))
bench::mark(phevaluator$evaluate_cards(50L, 46L, 42L, 38L, 34L))
```

Calling `evaluate_cards()` directly doesn't significantly change the results. Test once more with
random hands:

```{r random_hands}
bench::mark(eval_hand(deal_hand(deck)))
bench::mark(do.call(phevaluator$evaluate_cards, as.list(deal_hand(deck))))
```

Conclusion: using `phevaluator` via `reticulate::import()` is not a faster way to evaluate hands. It
is important to note that `phevaluator$evaluate_cards()` does more than `eval_hand()`, as
`phevaluator` ranks all poker hands and `eval_hand()` only determines the hand rank category.

# C/C++

Benchmark the `integer()` approach against the C/C++ implementation of
[PH Evaluator](https://github.com/HenryRLee/PokerHandEvaluator) using [Rcpp](https://www.rcpp.org).

The current version only implements `eval_hand_phe()`, which uses `EvaluateCards()` and
`describeCategory()` to return the card rank category.

## Evaluate

Test performance of `eval_hand()` and `eval_hand_phe()` with a single hand:

```{r eval_hand_phe}
bench::mark(eval_hand(test_hand))
bench::mark(eval_hand_phe(test_hand))
```

Somewhat surprisingly, `eval_hand_phe()` is only 2 times faster than `eval_hand()`, however,
`eval_hand_phe()` doesn't just evaluate hand rank category, it also determines exact hand rank.

Reviewing the benchmarks on the PH Evaluator `README` and on my own system, the compiled C/C++
implementation should be capable of about 70 million hands per second, while `eval_hand_phe()`
achieves about 1 million per second. This is likely due to the additional overhead of using R, and,
more importantly, the additional call to `describeCategory()`, as the benchmark
[code](https://github.com/HenryRLee/PokerHandEvaluator/blob/master/cpp/benchmark/benchmark.cc) only
calls `EvaluateCards()`.

A future implementation could implement the full `pheval` libraries and the C++ code in
[`card_sampler.h`](https://github.com/HenryRLee/PokerHandEvaluator/blob/master/cpp/benchmark/card_sampler.h)
to generate random hands in a standalone R package using
[Rcpp Modules](https://CRAN.R-project.org/package=Rcpp/vignettes/Rcpp-modules.pdf).
